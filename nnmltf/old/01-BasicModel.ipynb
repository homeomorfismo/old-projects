{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a93792f-ab2d-49ac-83e4-17e0b45a9bed",
   "metadata": {},
   "source": [
    "# 01 - Basic neural network\n",
    "From [this video](https://www.youtube.com/watch?v=w8yWXqWQYmU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bd87dab-dd2c-48cb-9670-525c78b9adb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3f7cf98-730a-4659-b5f9-8585f01ff41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y\n",
    "\n",
    "print(one_hot(np.matrix([1,2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d3b94b4-e02e-4c8a-970b-9f555c0c2166",
   "metadata": {},
   "outputs": [],
   "source": [
    "class neural_network():\n",
    "    \"\"\"\n",
    "    Basic NN form https://www.youtube.com/watch?v=w8yWXqWQYmU\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=True):\n",
    "        (self.train_x, self.train_y), (self.test_x, self.test_y) = mnist.load_data()\n",
    "        self.verbose = verbose\n",
    "        if verbose:\n",
    "            print('X_train: ', self.train_x.shape)\n",
    "            print('Y_train: ', self.train_y.shape)\n",
    "            print('X_test:  ', self.test_x.shape)\n",
    "            print('Y_test:  ', self.test_y.shape)\n",
    "        # Layers randomly initialized\n",
    "        # TODO to increase the number of layers\n",
    "        self.W = []\n",
    "        self.b = []\n",
    "        self.W.append(\n",
    "            np.random.rand(10, 784) - 0.5\n",
    "        )\n",
    "        self.W.append(\n",
    "            np.random.rand(10, 10) - 0.5\n",
    "        )\n",
    "        self.b.append(\n",
    "            np.random.rand(10, 1) - 0.5\n",
    "        )\n",
    "        self.b.append(\n",
    "            np.random.rand(10, 1) - 0.5\n",
    "        )\n",
    "\n",
    "    def plot_example(self, list):\n",
    "        \"\"\"\n",
    "        Visualize some data.\n",
    "        INPUT:\n",
    "        * list: A list of integers.\n",
    "        \"\"\"\n",
    "        for i in range(len(list):  \n",
    "            plt.subplot(330 + 1 + i)\n",
    "            plt.imshow(train_X[list[i]], cmap=pyplot.get_cmap('gray'))\n",
    "            plt.show()\n",
    "\n",
    "    def re_lu(self, z):\n",
    "        \"\"\"\n",
    "        ReLU (vec.) function.\n",
    "        \"\"\"\n",
    "        return np.maximum(z, 0.0)\n",
    "\n",
    "    def re_lu(z):\n",
    "        \"\"\"\n",
    "        Derivative of ReLU (vec.) function.\n",
    "        \"\"\"\n",
    "        return z > 0\n",
    "\n",
    "    def softmax(self, z):\n",
    "        \"\"\"\n",
    "        SOFTMAX (vec.) function.\n",
    "        \"\"\"\n",
    "        return np.exp(z)/sum(np.exp(z))\n",
    "\n",
    "    def forward_propagation(self, x):\n",
    "        \"\"\"\n",
    "        Forward propagation algorithm. Using one ReLU layer\n",
    "        and one softmax layer.\n",
    "        INPUT:\n",
    "        * x: data\n",
    "        OUTPUT:\n",
    "        * Z: list of the values before non-linear step.\n",
    "        * A: Output of a layer.\n",
    "        \"\"\"\n",
    "        data = np.reshape(x,784)\n",
    "        Z = []\n",
    "        A = []\n",
    "        Z.append(\n",
    "            self.W[0].dot(data) + self.b[0]\n",
    "        )\n",
    "        A.append(\n",
    "            self.re_lu(Z[0])\n",
    "        )\n",
    "        Z.append(\n",
    "            self.W[1].dot(A[0]) + self.b[1]\n",
    "        )\n",
    "        A.append(\n",
    "            self.softmax(Z[1])\n",
    "        )\n",
    "        return Z, A\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79769eb-a4bf-461d-aedc-437ed5d3c77e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
